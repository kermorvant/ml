{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on the MNIST dataset\n",
    "\n",
    "The goal of this notebook is to train  several classifiers on the classical MNIST database. This database is very popular in the machine learning community as a first test for new algorithms. This dataset is quite simple and artificial : having good results on MNIST does not mean that your algorithm is good, but having bad results surely means that you have to improve your algorithm. You can find reference results on the MNIST dataset [here](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "You can download the images from [here](http://dataiku.teklia.com/Images/MNIST/MNIST_all.tar_gz)\n",
    "\n",
    "\n",
    "### Libraries \n",
    "\n",
    "We will use the following libraries : \n",
    "* sklearn (scikit-learn) for machine learning algorithms\n",
    "* pandas for manipulating data\n",
    "* PIL for image processing\n",
    "* seaborn for graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "from pprint import pprint\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, neighbors, linear_model,svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "The first step is to extract features from the images to convert the image into a feature vectors. ALl the images  have the same size, 32x32 pixels. We reduce them to 8x8 pixels and use the 64 pixels values vector as the features. The function `extract_features_subresolution` process a given image and return the feature vector. The list of all the images is read from the file `Data/MNIST_all.csv`. The features are stored in a matrix `X` and the target class in a vector `y`.\n",
    "\n",
    "After loading the data, we plot the class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def extract_features_subresolution(img,img_feature_size = (8, 8)):\n",
    "    \"\"\"\n",
    "    Compute the subresolution of an image and return it as a feature vector\n",
    "\n",
    "    :param img: the original image (can be color or gray)\n",
    "    :type img: pillow image\n",
    "    :return: pixel values of the image in subresolution\n",
    "    :rtype: list of int in [0,255]\n",
    "\n",
    "    \"\"\"\n",
    "    # reduce the image to a given size\n",
    "    reduced_img = img.resize(\n",
    "        img_feature_size, Image.BOX).filter(ImageFilter.SHARPEN)\n",
    "    # return the values of the reduced image as features\n",
    "    return [i for i in reduced_img.getdata()]\n",
    "\n",
    "READ_N_SAMPLES = 5000 # use None for reading all samples\n",
    "# Change it to your MNIST images location\n",
    "IMAGES_DIR_PATH = '/Users/kermorvant/Work/ESILV/TP/TP_Classification'\n",
    "FEATURE_SIZE = 8\n",
    "all_df = pd.read_csv(\"../data/MNIST_all.csv\" ,header=None,names=['filename','class'],nrows=READ_N_SAMPLES)\n",
    "\n",
    "# plot class distriubtion\n",
    "sns.countplot(data=all_df,y='class')\n",
    "\n",
    "# loop on all the image path and extract features\n",
    "data = []\n",
    "for i_path in tqdm(all_df['filename']):\n",
    "    page_image = Image.open(os.path.join(IMAGES_DIR_PATH,i_path))\n",
    "    data.append(extract_features_subresolution(page_image,(FEATURE_SIZE,FEATURE_SIZE)))\n",
    "\n",
    "# convert to np.array\n",
    "X = np.array(data)\n",
    "y = all_df['class']\n",
    "\n",
    "print (\"Feature size\",X.shape)\n",
    "print (\"Target size\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to the images after feature sub-resolution and check that our dataset is correct (the lables correspond to the image) : \n",
    "\n",
    "You can change FEATURE_SIZE in the previous cell to see the impact of subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_plot = 18\n",
    "random_indices = random.sample(range(READ_N_SAMPLES), images_to_plot)\n",
    "\n",
    "sample_images = X[random_indices, :]\n",
    "sample_labels = y.loc[random_indices]\n",
    "\n",
    "fig, axes = plt.subplots(3,6, \n",
    "                        figsize=(10,5),\n",
    "                        sharex=True, sharey=True,\n",
    "                        subplot_kw=dict(adjustable='box-forced', aspect='equal')) \n",
    "\n",
    "for i in range(images_to_plot):\n",
    "    \n",
    "    subplot_row = i//6 \n",
    "    subplot_col = i%6  \n",
    "    ax = axes[subplot_row, subplot_col]\n",
    "\n",
    "    # plot image on subplot\n",
    "    plottable_image = np.reshape(sample_images[i,:], (FEATURE_SIZE,FEATURE_SIZE))\n",
    "    ax.imshow(plottable_image, cmap='gray_r')\n",
    "    \n",
    "    ax.set_title('Digit Label: {}'.format(sample_labels.iloc[i]))\n",
    "    ax.set_xbound([0,FEATURE_SIZE])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/dev/test split\n",
    "\n",
    "When training a classifier, the data **must** be separated into different sets : at least one training set and one test set. The split must be random and uniform, which means that the class distribution must be identical in the training and test sets.\n",
    "\n",
    "> * Use [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to create `X_train/y_train` and `X_test/y_test`. Use 80% of the data for training and 20% for testing.\n",
    "> * Train a [k-nearest neighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) classififier with k=1\n",
    "> * Test the k-NN with k= 1 on both the training and the test set. Print the score produced by [`clf.score()`](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)\n",
    "\n",
    "When evaluating a classifier, it is important to report the error rate both on the training and the classification set. These values are needed to understand what is wrong with the classifier and how to improve it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = None # YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(None, None, test_size=test_percent, random_state=42)# YOUR CODE HERE\n",
    "\n",
    "# create a kNN classifier with a given k\n",
    "k = None # YOUR CODE HERE\n",
    "clf = neighbors.KNeighborsClassifier(None,n_jobs=-1)# YOUR CODE HERE\n",
    "\n",
    "# Train the classifier on training set\n",
    "clf.fit(None,None)# YOUR CODE HERE\n",
    "\n",
    "# Predict and evaluate on train set\n",
    "_predicted = clf.predict(None)# YOUR CODE HERE\n",
    "print ('Train accuracy:',metrics.accuracy_score(None, _predicted))# YOUR CODE HERE\n",
    "# Predict and evaluate on test set\n",
    "_predicted = clf.predict(None)# YOUR CODE HERE\n",
    "print ('Test accuracy:',metrics.accuracy_score(None, _predicted))# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "\n",
    "The main parameter of the kNN algorithm is the number of neighbors (k). The best value for this parameter depends on the classification task and has to be found by trying different values and selecting the one with the best accuracy. However, this search for the best value **must not** be done on the set used to evaluate the classifier (the test set) but on a validation set. \n",
    "\n",
    "**Question** : \n",
    "\n",
    "\n",
    ">  * Create three sets : train set (60%), validation set (20%) and test set (20%), using twice `train_test_split`\n",
    ">  * Train a kNN classifier with different values of k and report the train/valid/test accuracy. \n",
    ">  * Select the is best value for k according to the accuracy on the dev set. Report the performance performance of the classifier on the test set for this value of k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train/dev/test sets\n",
    "# YOUR CODE HERE\n",
    "# Create validation set so that train = 60% , validation = 20% and test =  20%\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(None, None, test_size=None)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(None, None, test_size=None)\n",
    "\n",
    "\n",
    "#  list of k values to test\n",
    "k_values = [None] # YOUR CODE HERE\n",
    "\n",
    "# store the score in a dataframe\n",
    "df_scores = pd.DataFrame(columns=['train','dev','test'],index=k_values)\n",
    "\n",
    "# iterate on diff√©rent values of k\n",
    "for k in k_values:\n",
    "    print(\"k={}\".format(k))\n",
    "    \n",
    "    # create a kNN classifier with a given k\n",
    "    clf = neighbors.KNeighborsClassifier(None,n_jobs=-1) # YOUR CODE HERE\n",
    "    \n",
    "    # Train the classifier on training set\n",
    "    clf.fit(None,None) # YOUR CODE HERE\n",
    "    \n",
    "    # Compute the classification score on the different sets\n",
    "    for _name,_X,_y in [('train',X_train,y_train),('dev',X_dev,y_dev),('test',X_test,y_test)]:\n",
    "        df_scores.at[k,_name] = float(\"{:.2f}\".format(clf.score(_X,_y)))\n",
    "        clear_output(wait=True)\n",
    "        print(df_scores)\n",
    "_g = df_scores.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines\n",
    "\n",
    "Scikit-learn has a special class for dealing with hyperparamter optimization :  [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "We can optimize all the steps (feature extraction, classification) by defining a pipeline. \n",
    "\n",
    "To use this, we first convert our feature extraction into a transformer, so that it can be included in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class SubresolFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,col_name='filename', image_dir_path=IMAGES_DIR_PATH,dim=8):\n",
    "        self.col_name = col_name\n",
    "        self.image_dir_path = image_dir_path\n",
    "        self.dim = dim\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        data = []\n",
    "        for i_path in X[self.col_name]:\n",
    "            page_image = Image.open(os.path.join(self.image_dir_path,i_path))\n",
    "            data.append(extract_features_subresolution(page_image,(self.dim,self.dim)))\n",
    "        return np.array(data)\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we define the different steps of the pipeline and the different values of the parameters to be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', SubresolFeatures()),\n",
    "    ('clf', neighbors.KNeighborsClassifier())\n",
    "    \n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'features__dim': (8,),\n",
    "    'clf__n_neighbors':(1,)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the GridSearchCV object will be fitted on the train set with all the possible combinaison of parameter values and evaluated on a validation set with cross validation. The train/dev spit and the cross-validation is done automatically. Progress can be monitored with greater values of the parameter verbose.\n",
    "\n",
    "**Question** : \n",
    "\n",
    "\n",
    ">  *  reproduce the experiments on the parameter k from the previous question using GridSearchCV\n",
    ">  * add the exploration of different values of the feature dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected block\n",
    "\n",
    "    # Define the grid search to find the best parameters for both the feature extraction and the classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Split the dataframe with the file names in train/test\n",
    "    df_train_dev, df_test, y_train_dev, y_test = train_test_split(all_df, all_df['class'], test_size=0.2)\n",
    "    \n",
    "    print(\"Performing grid search\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    \n",
    "    # Run the grid search\n",
    "    grid_search.fit( None,  None) # YOUR CODE HERE\n",
    "    all_score = pd.DataFrame(grid_search.cv_results_)\n",
    "    print (all_score[['params','mean_train_score','mean_test_score']])\n",
    "    \n",
    "    # Print all experiments results\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    # Print best experiment results\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    # predict on test with best parameters\n",
    "    y_pred = grid_search.predict(None) # YOUR CODE HERE\n",
    "    print(classification_report(None, None)) # YOUR CODE HERE\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "\n",
    "We will now optimize a Support Vector Machine, SVM (S√©parateurs √† Vaste Marge in French) classifier on the MNIST database. These classifiers usually give very good results if they are well tuned.\n",
    "\n",
    "All the SVM classifier share a common parameter `C`: it controls how many examples are allowed to be badly classified during the optimization. For small values of C, some training example are allowed to be misclassified if the margin  (the distance between the separating line and the support vector) is large. For large values of C, the algorithm tries to minimize the number of misclassified training example, even if it lead to a small margin. The impact of the value for C is shown on the following figure : \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://kermorvant.github.io/csexed-ml/images/svm_values_for_C.png\" width=\"400\" >\n",
    "</p>\n",
    " \n",
    "\n",
    "**Question** : \n",
    "> * add a linear SVM classifier to the pipline :  [svm.SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) with the option `kernel='linear'`\n",
    "> * add the optimization of `C`  in GridSearchCV \n",
    "\n",
    "The RBF kernel (see the [scikit-learn kernels documentation](http://scikit-learn.org/stable/modules/svm.html#svm-kernels) has one more main parameter that must be optimized on the data :  `gamma`.\n",
    "\n",
    "`gamma` is a parameter controlling the *spread* of the RBF kernel : if `gamma` is small, the kernel takes into account many training samples and the decision boundary is smooth. When `gamma` is large, the kernel is focused on few training examples and the decision boundary is complex. The impact of `gamma` is illustrated on the following Figures : \n",
    "\n",
    "- `gamma` = 1\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://kermorvant.github.io/csexed-ml/images/svc_parameters_using_rbf_kernel_17_0.png\" width=\"300\" >\n",
    "</p>\n",
    "\n",
    "- `gamma` = 100\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://kermorvant.github.io/csexed-ml/images/svc_parameters_using_rbf_kernel_21_0.png\" width=\"300\" >\n",
    "</p>\n",
    "\n",
    "Moreover, for the RBF kernel, the data must be normalizedn you can use the [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to scale to [zero mean and unit variance](https://en.wikipedia.org/wiki/Feature_scaling#Standardization).  \n",
    "\n",
    "**Question** : \n",
    "> * add the StandardScaler as a pipeline step\n",
    "> * add the RBF kernel to the GridSearch [svm.SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) \n",
    "> * add the optimization of  `gamma` and `C` with values :  `C in [0.5,2,10]` and `gamma in [0.05,0.1,0.5]`. \n",
    "\n",
    "You can add a different kernel with its specific parameters this way : \n",
    "<pre>\n",
    "        {\n",
    "         'features__dim': (8,),\n",
    "         'clf__kernel': ['rbf'],\n",
    "         'clf__gamma': [1e-3, ],\n",
    "         'clf__C': [1,]\n",
    "        },\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', SubresolFeatures()),\n",
    "    ('clf', None)\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [\n",
    "        {\n",
    "        'features__dim': (8,),\n",
    "        'clf__kernel': ['linear'],\n",
    "        'clf__C': [1,]\n",
    "        }\n",
    "]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected block\n",
    "\n",
    "    df_train_dev, df_test, y_train_dev, y_test = train_test_split(all_df, all_df['class'], test_size=0.2)\n",
    "    \n",
    "    print(\"Performing grid search\")\n",
    "    grid_search = GridSearchCV(None, None, n_jobs=-1, verbose=2)# YOUR CODE HERE\n",
    "    grid_search.fit( None,  None)# YOUR CODE HERE\n",
    "    \n",
    "    # Print all experiments results\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    # Print best experiment results\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "    # predict on test with best parameters\n",
    "    y_pred = grid_search.predict(None)# YOUR CODE HERE\n",
    "    print(classification_report(None, None))# YOUR CODE HERE\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
