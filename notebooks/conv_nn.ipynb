{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "In this notebook, you will program the forward step of  convolution and max pooling layers. These layers are one of the basic elements needed to build a complete deep convolutional network.\n",
    "\n",
    "## Padding\n",
    "\n",
    "The padding is needed to keep the same image size through convolutions. It simply consist in adding zero values at the beggining and at the end of each lines and columns of the image. To implement the image padding, the numpy function [np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html) can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. \n",
    "    The padding is applied to the height and width of an image \n",
    "    \n",
    "     X: numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    params: pad: integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    returns: padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant') # YOUR CODE HERE\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all is correct !\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAADHCAYAAADxqlPLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10651f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "assert_equal(x.shape,(4, 3, 3, 2))\n",
    "assert_equal(x_pad.shape,(4, 7, 7, 2))\n",
    "assert_allclose(x_pad[1,1],[[0., 0.],[0., 0.], [0., 0.],[0. ,0.], [0. ,0.],[0., 0.], [0., 0.]])\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])\n",
    "print (\"all is correct !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution layer\n",
    "\n",
    "The principle of the convolution layer is illustrated on the following animation\n",
    "\n",
    "<img src=\"https://kermorvant.github.io/ml/images/conv_NN.gif\" style=\"width:600px;\">\n",
    "\n",
    "We will decompose the task in the following steps : \n",
    "1. `conv_single_step`: compute a single convolution step : this correspond to the computation of 1 value in one dimension in the output volume. It consider all the dimension of the previous layer and compute the convolution with the kernel. Note that the kernel has the same \"depth\" as the previous layer but all the values are summed.\n",
    "2. `conv_forward`: apply the single convolution step at each position and as many times as the depth of the output layer. \n",
    "\n",
    "### Single convolution step\n",
    "\n",
    "First, we implement a single convolution step : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    params: a_slice_prev: slice of input data of shape (f, f, n_C_prev)\n",
    "    params: W: convolution weights  of shape (f, f, n_C_prev)\n",
    "    params: b: bias weights of shape (1, 1, 1)\n",
    "    \n",
    "    returns: Z:  a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    # Element-wise product between a_slice and W\n",
    "    s = np.multiply(a_slice_prev,W)\n",
    "    print (s)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    print (Z)\n",
    "    print (b)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = np.add (Z,float(b))\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.19517964 -0.37757796 -0.15854148]\n",
      "  [ 0.37795303 -0.98874397  0.80402579]\n",
      "  [-0.36448112 -0.44654162  0.26766851]\n",
      "  [-0.23218928  0.41755949 -1.82351535]]\n",
      "\n",
      " [[ 0.24323087 -0.48116947  0.58154416]\n",
      "  [ 0.32786971 -0.08423431  0.06634126]\n",
      "  [ 0.04777032  0.88577236 -2.40548621]\n",
      "  [-1.59860247 -1.30199961 -0.25349124]]\n",
      "\n",
      " [[ 0.14417035 -0.5990611  -0.03878845]\n",
      "  [ 1.89231409  0.0820284   0.43912088]\n",
      "  [-0.1591475  -0.30233062  0.15277783]\n",
      "  [ 0.16968185 -0.12522861 -0.00519314]]\n",
      "\n",
      " [[-0.22156233  0.02789749 -1.11316672]\n",
      "  [ 0.280169   -0.02336965 -1.00256263]\n",
      "  [-0.89578144  0.31336883 -0.01906739]\n",
      "  [ 0.40686849  0.08085163  0.16243388]]]\n",
      "-6.655235775109145\n",
      "[[[-0.34385368]]]\n",
      "all is correct !\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "assert_almost_equal (Z,-6.99908945068)\n",
    "print (\"all is correct !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply convolution at multiple positions\n",
    "\n",
    "To apply the convolution at each position, you need to compute the dimensions of the output  layer. The dimensions are given by the following formula : \n",
    "\n",
    "The formulas relating the output shape of the convolution to the input shape is:\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_C = \\text{number of filters used in the convolution}$$\n",
    "\n",
    "Then you will need to locate the region of the image on which the convolution kernel is applied : \n",
    "\n",
    "<img src=\"https://kermorvant.github.io/ml/images/cnn_vert_horiz_boundaries.png\" style=\"width:350px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    params: A_prev:  output activations of the previous layer of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    params: W: convolution weights  of shape (f, f, n_C_prev, n_C)\n",
    "    params: bias: weights of shape  (1, 1, 1, n_C)\n",
    "    params: hparameters: python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    returns: Z:  conv output of shape (m, n_H, n_W, n_C)\n",
    "    cache:  cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Retrieve dimensions from A_prev's shape \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" \n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    n_H = int((n_H_prev+2*pad-f)/2.0+1)\n",
    "    n_W = int((n_W_prev+2*pad-f)/2.0+1)\n",
    "\n",
    "    # Initialize the output volume Z with zeros. \n",
    "    Z = np.zeros((m,n_H,n_W,n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev,pad)\n",
    "    \n",
    "    # loop over the batch of training examples\n",
    "    for i in range(m):                \n",
    "        # Select ith training example's padded activation\n",
    "        a_prev_pad = A_prev_pad[i,:,:,:]             \n",
    "        # loop over vertical axis of the output volume\n",
    "        for h in range(n_H): \n",
    "            # loop over horizontal axis of the output volume\n",
    "            for w in range(n_W):                     \n",
    "                # Find the corners of the current \"slice\"             \n",
    "                vert_start = h*stride\n",
    "                vert_end = vert_start+f\n",
    "                horiz_start = w*stride\n",
    "                horiz_end = horiz_start+f\n",
    "                for c in range(n_C):   \n",
    "                    # loop over channels (= #filters) of the output volume\n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron.\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c],b[:,:,:,c])\n",
    "                                        \n",
    "    # dimension check\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all is correct !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\"stride\": 2}\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "assert_almost_equal(np.mean(Z),0.0489952035289)\n",
    "assert_allclose(Z[3,2,1],[-0.61490741 ,-6.7439236 ,-2.55153897 ,1.75698377, 3.56208902, 0.53036437, 5.18531798 ,8.75898442])\n",
    "assert_allclose(cache_conv[0][1][2][3],[-0.20075807, 0.18656139, 0.41005165])\n",
    "print (\"all is correct !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layer\n",
    "\n",
    "The second kind of layer often used in deep convolution neural networks is the max pooling layer. Other kind of pooling exists (max, average, L2), but we will focus on max pooling.\n",
    "\n",
    "The compution of a ma pooling layer with size f=2 and stride=2 is given below : \n",
    "\n",
    "<img src=\"https://kermorvant.github.io/ml/images/cnn_max_pooling.png\" style=\"width:350px;\">\n",
    "\n",
    "\n",
    "Since the single operation is a simple max over values and that the skeleton is similar to that of the convolution, we will directly implement the application of max pooling at mutliple position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    params: A_prev: input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    params: hparameters:  dictionary containing \"f\" and \"stride\"\n",
    "    \n",
    "    \n",
    "    returns: A:  output of the pool layer  of shape (m, n_H, n_W, n_C)\n",
    "    cache: cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    # loop over the training examples\n",
    "    for i in range(m):         \n",
    "        # loop on the vertical axis of the output volume\n",
    "        for h in range(n_H):      \n",
    "            # loop on the horizontal axis of the output volume\n",
    "            for w in range(n_W):   \n",
    "                # loop over the channels of the output volume\n",
    "                for c in range (n_C):            \n",
    "                    \n",
    "                    # Find the boundaries of the current \"slice\" \n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start+f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start+f\n",
    "                    \n",
    "                    # Use the boundaries to define the current slice on the ith training example of A_prev, channel c. \n",
    "                    a_prev_slice = A_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    \n",
    "                    # Compute the max pooling operation on the slice. \n",
    "                    A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all is correct !\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "assert_allclose(A,[[[[ 1.74481176, 0.86540763 ,1.13376944]]] ,[[[ 1.13162939, 1.51981682, 2.18557541]]]])\n",
    "print (\"all is correct !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know precisely the details of the convolution and max pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
