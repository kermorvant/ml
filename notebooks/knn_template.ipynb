{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, neighbors, linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "The first step is to extract features from the images to convert the image into a feature vector. The images all have the same size, 32x32 pixels. We reduce them to 8x8 pixels and use the 64 pixels values vector as the features. The function `extract_features_subresolution` process a given image and return the feature vector. The list of all the images is read from the file `Data/MNIST_all.csv`. The features are stored in a matrix `X` and the target class in a vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter\n",
    "import os\n",
    "DATA_PATH = 'Data/'\n",
    "DEFAULT_SUBRESOLUTION = (8,8)\n",
    "def extract_features_subresolution(img,img_feature_size = DEFAULT_SUBRESOLUTION):\n",
    "    # reduce the image to a given size\n",
    "    reduced_img = img.resize(\n",
    "        img_feature_size, Image.BOX).filter(ImageFilter.SHARPEN)\n",
    "    # return the values of the reduced image as features\n",
    "    return [i for i in reduced_img.getdata()]\n",
    "\n",
    "# load the list of all the images with their class\n",
    "all_df = pd.read_csv(\"Data/MNIST_all.csv\",header=None,names=['filename','class'])\n",
    "all_df = all_df.sample(frac=1).reset_index(drop=True)\n",
    "file_list = all_df['filename']\n",
    "\n",
    "# target is the class\n",
    "y = all_df['class']\n",
    "\n",
    "# extract the features \n",
    "data = []\n",
    "for i_path in tqdm(file_list):\n",
    "    page_image = Image.open(os.path.join(DATA_PATH,i_path))\n",
    "    data.append(extract_features_subresolution(page_image,DEFAULT_SUBRESOLUTION))\n",
    "X = np.array(data)\n",
    "\n",
    "# Check the size\n",
    "# Feature size should be DEFAULT_SUBRESOLUTION\n",
    "print (\"feature size\",X.shape[1])\n",
    "print (\"number of samples\",X.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(## ADD PARAMETERS)\n",
    "\n",
    "# Define a kNN classifier with k = 1\n",
    "## ADD YOUR CODE HERE\n",
    "    \n",
    "# Train the classifier on training set\n",
    "## ADD YOUR CODE HERE\n",
    "    \n",
    "# Print the acuracy on the train et test set\n",
    "## ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Split train/dev/test\n",
    "X_train, X_test, y_train, y_test = # ADD YOUR CODE HERE\n",
    "# Create validation set so that train = 60% , validation = 20% and test =  20%\n",
    "X_train_hyper, X_valid_hyper, y_train_hyper, y_valid_hyper = # ADD YOUR CODE HERE\n",
    "\n",
    "# select a smaller sample to train\n",
    "sub_size = 5000 # Change this value if you want\n",
    "# take the first samples : this is OK because we shuffled the file list.\n",
    "X_train_hyper_sub = X_train_hyper[:][:sub_size]  \n",
    "y_train_hyper_sub = y_train_hyper[:][:sub_size]\n",
    "\n",
    "#  list of k values to test\n",
    "k_values = # ADD YOUR CODE HERE\n",
    "\n",
    "# store the score in a dataframe\n",
    "df_scores = pd.DataFrame(columns=['train','valid','test'],index=k_values)\n",
    "\n",
    "# iterate on diff√©rent values of k\n",
    "for k in k_values:\n",
    "    \n",
    "    # create a kNN classifier with a given k\n",
    "    clf = neighbors.KNeighborsClassifier(k,n_jobs=-1)\n",
    "    \n",
    "    # Train the classifier on training set\n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    # Compute the classification score on the different sets\n",
    "    for _name,_train_set,_test_set in [('train',X_train_hyper_sub,y_train_hyper_sub),('valid',X_valid_hyper,y_valid_hyper),('test',X_test,y_test)]:\n",
    "        _accuracy = # ADD YOUR CODE HERE\n",
    "        df_scores.at[k,_name] = float(\"{:.2f}\".format(_accuracy))\n",
    "        # print the dataframe with score\n",
    "        clear_output(wait=True)\n",
    "        print(df_scores)\n",
    "\n",
    "# plot the score for different values of k\n",
    "_g = df_scores.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
